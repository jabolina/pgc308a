{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 4\n",
    "\n",
    "O objetivo dessa parte seria focado na reducao de parametros para a criacao de um modelo adequado, identificando\n",
    "quais metricas mais se correlacionam ao numero de quadros na saida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Construct a training set and a test set from the trace as above.\n",
    "\n",
    "2. Method 1: Build all subsets of the feature set X that contain either one or two features (i.e., device statistics). Compute the models for each of these sets for linear regression over the training set. Plot a histogram of the error values (NMAE) of all the models for the test set. Identify the feature set that produces the model with the smallest error and give the device statistic(s) in this set.\n",
    "\n",
    "3. Method 2: Linear univariate feature selection. Take each feature of $X$ and compute the sample correlation of the feature with the corresponding $Y$ value over the training set. For observations $x_i, y_i$, the sample correlation is computed as $\\frac{1}{m}\\sum_{i=1}^m\\frac{(x_i - \\bar{x})(y_i - \\bar{y}}{(\\sigma_X * \\sigma_Y)}$ whereby $\\bar{x}$ and $\\bar{y}$ are sample means and $m$ is the size of the training set; $\\sigma_X$ is the standard deviation $\\sqrt{(\\frac{1}{m}\\sum_{i=1}^m(x_i - \\bar{x})^2)}$ and likewise for $\\sigma_Y$. The correlation values fall into the interval [âˆ’1, +1]. Rank the features according to the square of the correlation values; the top feature has the highest value. Build nine feature sets composed of the top $k$ features, $k = 1..9$. Compute the model for each of these nine sets for linear regression over the training set and compute the error (NMAE) of these models over the test set. Produce a plot that shows the error value in function of the set $k$.\n",
    "\n",
    "4. Describe your observations and conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criado 1023 sub-sets de dados\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, combinations\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pp\n",
    "\n",
    "class Subset:\n",
    "    def __init__(self, x_df, y_df, size, columns):\n",
    "        self.columns = columns\n",
    "        self.data = x_df[columns]\n",
    "        x_train, x_test, y_train, y_test = \\\n",
    "            self.data[:size], self.data[size:], y_df[:size], y_df[size:]\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def data_width(self):\n",
    "        return len(self.columns)\n",
    "\n",
    "def superset(values):\n",
    "    return map(lambda t: list(t), chain.from_iterable(combinations(values, r) for r in range(len(values) + 1)))\n",
    "    \n",
    "def create_subsets(x, y):\n",
    "    subset_columns = list(filter(lambda t: len(t) > 0, superset(x.columns)))\n",
    "    return [Subset(x, y, 2520, columns) for columns in list(subset_columns)]\n",
    "\n",
    "\n",
    "x_data = pd.read_csv('./data/X.csv')\n",
    "y_output = pd.read_csv('./data/Y.csv')\n",
    "\n",
    "subsets = create_subsets(x_data, y_output)\n",
    "print(f\"Criado {len(subsets)} sub-sets de dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo com as features ['sum_intr.s', 'tcpsck'] possui NMAE: 0.07631804644716354\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def absolute_errors(expected, found):\n",
    "    return [abs(y1 - y2) for (y1, y2) in zip(expected, found)]\n",
    "\n",
    "def mean_errors(expected, found):\n",
    "    return sum(absolute_errors(expected, found)) / len(expected)\n",
    "\n",
    "def normalized_mean_absolute_error(expected, found):\n",
    "    return mean_errors(expected, found) / found.mean()\n",
    "\n",
    "class TrainedModel:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.model = linear_model.LinearRegression()\n",
    "        self.predicted = []\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.fit(self.data.x_train, self.data.y_train['DispFrames'])\n",
    "        \n",
    "    def predict(self):\n",
    "        self.predicted = self.model.predict(self.data.x_test)\n",
    "        \n",
    "    def calculate_nmae(self):\n",
    "        return normalized_mean_absolute_error(self.data.y_test['DispFrames'], self.predicted)\n",
    "    \n",
    "filtered_subsets = list(filter(lambda subset: subset.data_width() <= 2, subsets))\n",
    "\n",
    "def create_and_train_model(data):\n",
    "    model = TrainedModel(data)\n",
    "    model.train()\n",
    "    model.predict()\n",
    "    return model, model.calculate_nmae()\n",
    "\n",
    "models = [create_and_train_model(subset) for subset in filtered_subsets]\n",
    "\n",
    "minimum_model = min(models, key = lambda t: t[1])\n",
    "\n",
    "print(f\"O modelo com as features {minimum_model[0].data.columns} possui NMAE: {minimum_model[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
